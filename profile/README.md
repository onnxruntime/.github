<p align="center"><img width="50%" src="https://onnxruntime.ai/images/svg/ONNX-Runtime-logo.svg" /></p>

**Supercharge your machine learning with ONNX Runtime, a cross-platform inference and training accelerator**.

**ONNX Runtime inference** can enable faster customer experiences and lower costs, supporting models from deep learning frameworks such as PyTorch and TensorFlow/Keras as well as classical machine learning libraries such as scikit-learn, LightGBM, XGBoost, and more. ONNX Runtime is compatible with a wide range of hardware, drivers, and operating systems, and delivers unparalleled performance by leveraging hardware accelerators where applicable alongside intelligent graph optimizations and transforms. [Learn more &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-inferencing)

**ONNX Runtime training** can accelerate the model training time on multi-node NVIDIA GPUs for transformer models. Experience faster training with a simple one-line addition to your existing PyTorch scripts. [Learn more &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-training)


## Get Started & Resources

[![ONNXRuntime Website](https://img.shields.io/badge/ONNXRuntime.ai-0078D7?style=for-the-badge&logo=Microsoft-edge&logoColor=white&link=https://onnxruntime.ai)](https://onnxruntime.ai)
[![ONNXRuntime Docs](https://img.shields.io/badge/Documentation_and_Tutorials-000000?style=for-the-badge&logo=mdnwebdocs&logoColor=white&link=onnxruntime.ai/docs)](onnxruntime.ai/docs)
[![ONNXRuntime Youtube](https://img.shields.io/badge/Video_Tutorials-FF0000?style=for-the-badge&logo=youtube&logoColor=white&link=https://www.youtube.com/onnxruntime)](https://www.youtube.com/onnxruntime)
[![ONNXRuntime Blogs](https://img.shields.io/badge/Blogs-258ffa?style=for-the-badge&logo=Microsoft&logoColor=white&link=onnxruntime.ai/blogs)](onnxruntime.ai/blogs)

**Sample and tutorial repositories:**

[![ONNXRuntime Docs](https://img.shields.io/badge/ONNX_RUNTIME_Inferencing-666666?style=for-the-badge&logo=visual%20studio%20code&logoColor=white&link=https://github.com/microsoft/onnxruntime-inference-examples)](https://github.com/microsoft/onnxruntime-inference-examples)
[![ONNXRuntime Docs](https://img.shields.io/badge/ONNX_RUNTIME_Training-666666?style=for-the-badge&logo=visual%20studio%20code&logoColor=white&link=https://github.com/microsoft/onnxruntime-inference-examples)](https://github.com/microsoft/onnxruntime-inference-examples)
